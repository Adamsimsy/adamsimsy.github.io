{"pages":[{"title":"","permalink":"http://adamsimsy.com/google0dc392fd4b4dfbf1.html","text":"google-site-verification: google0dc392fd4b4dfbf1.html"},{"title":"404. Page not found","permalink":"http://adamsimsy.com/404/index.html","text":"Looks like the robots in the cloud couldn’t find what you were looking for. Try navigating to the blog home or use the search in the top right."},{"title":"About","permalink":"http://adamsimsy.com/about/index.html","text":"Connect with me: Github： Adamsimsy Twttier: Adamsimsy"}],"posts":[{"title":"Publish a ASP.NET Core Web App to Azure using Github Actions","permalink":"http://adamsimsy.com/2020/03/29/publish-a-aspnet-core-web-app-to-azure-using-github-actions/","text":"I’ve been working a lot with Azure DevOps to build and deploy many different types of applications to Azure Cloud, On-premise servers and handheld devices. But i thought it would be interesting to try and compare this to Github Actions which I believe is underpinned by Azure DevOps as it is owned by Microsoft. Create a Vanilla ASP.NET Core 3.1 web appSo the app i choose to build and deploy was a ASP.NET Core 3.1 template app. I created a clean Github repo which can be found here. To do this i used the following command and specified the netcoreapp Framework version as i had multiple installed:1dotnet new mvc -o Website --framework netcoreapp3.1 This should give you something like the following: Setup a new Github Actions WorkflowWhilst logged into Github, navigated to your repository and then click Actions. You have many workflow templates to choose from including a “.NET Core” example: However, select “Set up a worflow yourself” which will give you the following: Accept the default path and “main.yml” path in your repo. Then paste in the following snippet which is also available from here:123456789101112131415161718192021222324252627282930name: .NET Coreon: push: branches: [ master ] pull_request: branches: [ master ] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup .NET Core uses: actions/setup-dotnet@v1 with: dotnet-version: 3.1.101 - name: Publish run: dotnet publish source/Website/Website.csproj --configuration Release -o ./output/ - name: deploy to azure web app uses: azure/webapps-deploy@v2 with: app-name: aspnetcore-github-actions-publish-to-azure publish-profile: $&#123; &#123; secrets. &#125; &#125; package: ./output/ Optionally, if you want to attach the build as an artifact to the Github Action build, you can do this with the following snippet added to your “main.yml”:12345- name: Publish artifact uses: actions/upload-artifact@v1 with: name: aspnetcore-webapp path: ./output/ You’ll then see the artifact attached as follows: However, I don’t believe at this time you can specify the artifact as the package path for the Azure deployment action. I tried several configurations, review the documentation and the code for the action on Github. Please comment if you work this part out! Create an Azure Web App and configure publishing profile in Github secretsNext you’ll need to create a new Azure Web App. I won’t take you through these steps and there are many tutorials online. But if you are testing, i recommend setting up a Azure trial account and deploying a free Dev/Test App Service Plan on the F1 tier. Once you have your web app, you’ll then need to get your publishing profile. Do this by clicking “Get publish profile”: This will give you an XML like the following: 123&lt;publishData&gt;&lt;publishProfile profileName=\"test-github-action-webapp - Web Deploy\" publishMethod=\"MSDeploy\" /&gt;...&lt;/publishData&gt; Now you need to configure your secret in Github. In your repository click Settings &gt; Secrets. Then create a new secret called “azureWebAppPublishProfile” and paste in the full XML from your publish profile from your Azure Web App. See the following example: You’ll also need to make sure the name of your web app (in my example “aspnetcore-github-actions-publish-to-azure”) is reflected in your “main.yml” otherwise it won’t deploy correctly. Now trigger a build to deploy your web app to AzureYou can either trigger a build manually in Github by re-running a previous job: Alternatively, just make a new commit to your master branch as per the branch trigger in the action workflow “main.yml” file. Your web app is now deployed to Azure using Github actionsYou’ll now be able to view your published Azure Web App that was built and deployed using Github actions. You can see my demo web app at https://aspnetcore-github-actions-publish-to-azure.azurewebsites.net. I hope this article is helpful in getting you going with your first ASP.NET Core Web App deployed to Azure using Github Actions."},{"title":"Sitecore Symposium 2018: When Sitecore Squadrons feel the need for speed!","permalink":"http://adamsimsy.com/2018/10/12/sitecore-symposium-2018-when-sitecore-squadrons-feel-the-need-for-speed/","text":"At this year’s Sitecore Symposium 2018 in Florida, I shared the story of how a Sitecore team flew higher than ever before to deliver a robust and rapid to deploy Sitecore platform. This platform, enabled Open Universities Australia to achieve “Best Business ROI Sitecore Experience Award”. The key idea is that “No matter what your release practices are or the maturity of your Sitecore solution, you can go faster with Sitecore to deliver better customer experiences and business value with some tools, tactics, planning and investment.” Please feel free to download my slides from Dropbox here and connect with me on Twitter @adamsimsy if you’d like to find out more."},{"title":"Accelerate your Sitecore release pipeline by consolidating environments used for testing and verification","permalink":"http://adamsimsy.com/2018/06/19/accelerate-your-release-pipeline-by-consolidating-environments-used-for-testing-and-verification/","text":"Today, all agile teams are trying to deliver their features into production faster to keep up with rapidly changing customer and business demands. A big contributing factor to feature delivery time is the release pipeline and the number of environments that the feature has to be deployed to. Typical environments being: Development Integration or SIT Test UAT Pre-production Production Each environment taking time to deploy, execute testing, management of data and coordination between teams. A workshop approach to environment consolidationAn organisation I have been working with has been investing in optimizing their release pipeline. Striving to be able to deploy multiple times a day and reduce the feature lead time into production. We felt that we could consolidate the environments in the release pipeline to accelerate our delivery. The problem was that it was difficult to agree which environments could be removed. Especially with multiple teams, responsible for multiple systems, which required environment alignment for verification of system integrations. So we started with the question… “What testing or verification do we need to get a release into production?” To answer this question, we decided to run a workshop with 3 key steps: List all the types of the testing Agree on the ubiquitous (testing) language Organizing the testing groups We started the workshop by placing cards up on a wall and I’ll take you through each step so that you might be able to run a similar exercise with your team. Workshop step 1 - List all the types of testing and verificationThe first step began by equipping everyone with everyone’s favorite agile tools. Then each of us took 5 minutes to write all the types of testing or verification we felt was required to get a feature from development to production. We then stuck all of these on a wall. We soon had a very interesting collection from a diverse set of skills and teams who are involved and responsible in getting a feature to production including developers, production owners, business analysts, testers, operations and release managers. Workshop step 2 - Ubiquitous (testing) languageWe took a short break to grab some coffee before reconvening to agree on a common set of language for testing. Our Ubiquitous (testing) language. This was the most challenging and interesting part of the workshop. We began organizing the tickets into groups as a team. Picking one ticket at a time and asking the person who wrote the ticket what the type of testing meant to them. We then discussed and agreed which group it should sit in. It was difficult to get going, but as we discussed more tickets, we began to quickly gain a consensus on what we meant by each type of testing. After we had grouped the types of testing, we agreed on a name for the type of testing or our ubiquitous (testing) language. The result can be seen below. The most interesting question and discussion during the exercise was “What do we mean by User Acceptance Testing (UAT)?”. After we had finished we had a good understanding of what UAT was and wasn’t to us as we had our types of testing in categories. The consensus was, UAT was acceptance testing of a feature on an integrated environment, which was the responsibility of the team or squad that produced the feature. Workshop step 3 - Organizing the testing groupsAfter lunch, we met again to begin the final step of the workshop, organizing our testing and verification into a logical order and where we felt they could be executed together. We tried to avoid naming these groups at first but naturally found we had some of the original environments in our delivery pipeline. The result can be seen below. Some key points from this step and what we had agreed on above: DEV environment Where teams or squads would carryout acceptance testing before changes are merged into the main source control trunk and continuously delivered into our pipeline Build server Would continue to execute unit tests and code analysis on code commit. Failing a build or deployment with any regression The Pipeline Our pipeline shrunk down to INT, TST and PRD and continuous deploying features merged into the main trunk to INT INT environment All automated tests would run here after a deployment TST environment Where the bulk of our testing would happen including any current manual verification. With the aim to automate moving forward. The environment would be an exact replica of production with automated roll back of non-sensitive data, removing the need for a pre-production environment PRD environment continuous health checks, synthetics and monitoring. Where possible any types of automated testing executed on earlier environments What was key to this step and enabled us to consolidate environments, was challenging the need for traditional environments and where the testing was executed. Trying to utilize our consolidated environments and make better use of TST which would be a full replica of production. ConclusionFrom running through this exercise in 3 discrete steps or sessions, as a team we were able to gain a consensus on the types of testing we required to get features into production. This was an important step for us as some people had slightly different but valid ideas about what a type of testing would validate, who would be responsible to execute it, what data was required and where it could run. This enabled us to then consolidated where testing and verification would be executed to move from 6 to 4 environments (not including Build) which would have significant savings in: Time to release Effort and cost to provision and manage the environments Possible license or service savings We’re now busy putting this into action and changing our deployment pipeline, infrastructure as code environment provisioning and development practices. It might not be possible to do this in every organization as there may be strict governance, control gates and specialized teams dedicated to testing in certain environments. Banks for example you’d have a hard time making any radical changes to established processes and controls in the release process. But you could focus on other factors to enable faster delivery such as trunk based development, componentization and feature flags. More on this hopefully in future blog posts. But if you feel there is an opportunity to consolidate the number environments, with your team start with the questions “what testing or verification do we need to get a release into production?” and “can the testing be grouped and executed on a smaller number of environments?” which might be provisioned differently."},{"title":"Convert Hyper-V generation 2 vhdx disk to generation 1 vhd disk","permalink":"http://adamsimsy.com/2018/06/16/convert-hyper-v-generation-2-vhdx-disk-to-generation-1-vhd-disk/","text":"If you ever find you need to downgrade a Windows hyper-v machine from generation 2 .vhdx to a generation .vhd, this unfortunately doesn’t work by simply using the Hyper-V Manager edit and convert utility. What you’ll get is a blinking cursor when you attached the converted .vhd disk to a new generation 1 VM. You can try attaching a Windows installation ISO, booting into the recovery options, using command prompt and “bootrec /fixmbr” tools but this won’t work because the drive is still configured to boot using GPT/UEFI instead of MBR. This is where I got stuck until I found the following steps that worked. The solutionConvert the disk to generation 1Firstly you will need to convert your generation 2 .vhdx to generation 1 .vhd as above. This might take some time to convert. You then need to attach this image using windows disk management. Do this by clicking “Action &gt; Attach VHD”. This is ready for a step later for the clone. Create new target vhdNext create a new “Action &gt; Create VHD” and use the following settings: Initialize new disk for MBRThen initialize the disk by right clicking on the new drive and then use MBR (Master Boot Record) option. Create a new simple volumeYou then need to create a New Simple Volume by right clicking on the disk and selecting a drive letter and all the default options as below: You’ll then see something like this in disk management with DISK 1 (the converted vhd drive which won’t boot due to GPT) and DISK 2 (the empty vhd which is formatted for MBR). Clone from converted gpt disk to target mbr vhdNext we need to clone the windows volume from the converted “gpt vhd” to the “mbr vhd”. The only way I found to do this was to download and install a tool called AOMEI Backupper from https://www.backup-utility.com/downloads.html. This looks like a reputable tool from https://www.tenforums.com/software-apps/85310-aomei-backupperfull-exe-safe.html. Use the Clone partition option with the options as below. You’ll find this runs surprisingly quickly. Attach disk to vm and fixmbrNow create a new virtual machine in Hyper-v Manager that has attached the new vhd that was cloned. Also attach a Windows installation ISO to this VM, boot into the VM and use the recovery option. We need to do this to fix the MBR so we can boot. Do this by executing the following commands in recovery command prompt in the following order:123456789diskpartdiskpart &gt; Select volume 1diskpart &gt; activediskpart &gt; exitcd /d c:\\bootrec /fixmbrbootrec /fixbootbootrec /rebuildbcd (select yes for [1] c:\\windows)Exit Finished with bootable vmStop the VM, eject the Windows ISO and then start the VM and you should get windows booting again on generation 1 vhd using mbr :)"},{"title":"Sitecore content and components missing after layout change","permalink":"http://adamsimsy.com/2017/11/25/sitecore-content-and-components-missing-after-layout- change/","text":"I came across this issue recently after some changes were made to Sitecore layouts and placeholder names. A change was made to switch a template called ‘General page’ to use a new layout container which we had taken from Habitat. We switched from ‘ArticleAsideRight.cshtml’ to ‘1 Column.cshtml’. After changing, the developer working with me found that the authored content was missing for the ‘General page’ so he changed the placeholder on ‘1 Column.cshtml’: 1234From@Html.Sitecore().DynamicPlaceholder(\"col-huge\", Model.Rendering.GetUseStaticPlaceholderNames())To@Html.Sitecore().DynamicPlaceholder(\"col-wide-1\", Model.Rendering.GetUseStaticPlaceholderNames()) This worked great, except we had another template called ‘Landing page’ using this layout and the original placeholder. This would have been fine for any new content or content which hadn’t had components added, as we updated the standard values for the template. However our authors had already been adding content and component renderings with datasources and placeholders which referred to the old placeholder name ‘col-huge’. We found a few solutions: [1] Ask the authors to add components again and point for the datasources they added - Not an option for us and the authors.[2] Add the placeholder definition for both to the same layout. This was a quick fix but we’d have a mix of placeholders in ‘Final Renderings’ and would make maintaining presentation details and placeholders in the future tricky.[3] Update the ‘Final Renderings’ field to use the new placeholder name using PowerShell We went for the final option and used the code snippet that can be found on my Sitecore PowerShell Examples GIST. Beware! Make sure you test this script thoroughly before running against content editors content as they’ll be more upset with you than if you asked then to add their components again. Ohh and make sure you take a backup first! :)"},{"title":"Reset Sitecore admin password and account","permalink":"http://adamsimsy.com/2017/11/25/reset-sitecore-admin-password-and-account/","text":"I recently managed to lock out my Sitecore local admin account when using the Sitecore PowerShell module. It did this without warning when the elevated privileges stopped working correctly. Anyway from a few various sources I found some examples of how to reset the password. But what was required was to also to set IsLockedOut value. If you ever find your account locked out, try running the following. 1234567UPDATE [aspnet_Membership] SET [Password]='qOvF8m8F2IcWMvfOBjJYHmfLABc=', [PasswordSalt]='OM5gu45RQuJ76itRvkSPFw==', [IsApproved] = '1', [IsLockedOut] = '0'WHERE UserId IN (SELECT UserId FROM dbo.aspnet_Users WHERE UserName = 'sitecore\\Admin') Enjoy!"},{"title":"Sitecore SC_ANALYTICS_GLOBAL_COOKIE missing","permalink":"http://adamsimsy.com/2017/11/12/sitecore-sc-global-anaytics-cookie-missing/","text":"This is an uncommon issue and one that is easy to overlook if you’ve recently deployed Sitecore into production. But you find that the persistant cookie “SC_ANALYTICS_GLOBAL_COOKIE” which Sitecore uses to track contacts across sessions in the xDB is missing. This causes a number of issues, but the main one being is that if a visitor returns to the website, a new contact is created as Sitecore cannot relate the two sessions using this unique visitor id. The cookie you expect to see is: There are a number of reasons why this might not appear: [1] Sitecore analytics has been disabled using the setting “Analytics.Enabled” or “Xdb.Enabled” depending on your version of Sitecore[2] The “@Html.Sitecore().VisitorIdentification()” razor view helper is missing[3] Your license is for CMS only and not xDB[4] Failure to connect to MongoDB[5] You have configured your site domain to a different one being used by external website visitors. This sometimes happens if you are using a load balancer or proxying. What you’ll find is that the “Set-Cookie” response header is trying to set the cookie for the wrong domain which your browser will ignore and not store. See example below. The final one being a tricky one to hunt down, so i thought i’d share the steps i went through to find the solution. I hope this saves someone else some time."},{"title":"Moving my blog from Jekyll to Hexo","permalink":"http://adamsimsy.com/2017/03/12/Moving-my-blog-from-Jekyll-to-Hexo/","text":"For some time I have been meaning to begin blogging about my Sitecore and development experiences to share with the community. Around a year ago i created a new blog using GitHub pages and Jekyll which was straight forward. I made a few posts but as it was a really simple and not attractive blog, I was never keen to share my posts or write new ones. The reason it was so simple was because there are limitations with Jekyll themes and plugins running on GitHub pages, which GitHub renders on the fly. So again, recently I decided I wanted to start blogging a lot more to engage with the Sitecore community. So, first thing first…I wanted to find a blogging engine that i was happy with. I considered the following and did some research into what others in the community were using: WordPress Blogger Ghost Medium These I looked at and thought were good platforms, but I liked the power you had over your blog with Jekyll. I then had bit of a chat with Kam about his blog and he suggested Hexo which is a “A fast, simple &amp; powerful blog framework” which can also run on GitHub. I was able to get a blog up and running very quickly by following the Getting started guide for Hexo and GitHub pages. Both Jekyll and Hexo use markdown format for posts which made it easy to keep my old posts. But for me the Hexo had the following advantages over Jekyll: Hexo uses NodeJS where Jekyll uses Ruby (less stuff to install and more familiar with Node) You generate Hexo blogs locally and then deploy them to your GitHub pages repo. Jekyll with GitHub renders on the fly which causes plugin and theme limitations Better themes and plugins for Hexo which are easy to install Within a few hours I was able to deploy Hexo, understand how it works and to install and customise a theme as you can see below. I’m pretty happy with what I have and now looking forward to blogging regularly!"},{"title":"Differences between IaaS, PaaS and SaaS","permalink":"http://adamsimsy.com/2016/08/01/difference-between-iaas-paas-and-saas/","text":"Over the last few years working as an SA i’ve helped to architect solutions that use more and more cloud services and very often see the following terms used: IaaS or Infrastrcture as a Service PaaS or Platform as a Service SaaS or Software as a Service Just from looking at the names of each service types, most technical people can work out what is provided by each. But unfortunately sometimes people are unsure of the differences, paticularly where IaaS ends and PaaS starts. So i thought i’d put together a simple illustration which may help someone looking for a quick overview of the differences. IaaS PaaS SaaS Applications Applications Applications Data Data Data Runtime Runtime Runtime Middleware Middleware Middleware O/S O/S O/S Virtualisation Virtualisation Virtualisation Servers Servers Servers Storage Storage Storage Networking Networking Networking Managed by vendor** You manage"},{"title":"Sitecore scheduled tasks not running","permalink":"http://adamsimsy.com/2016/07/26/sitecore-scheduled-tasks-not-running/","text":"Today i’ve been trying to understand why I couldn’t configure a scheduled task to run a Sitecore Powershell script. I found many useful articles which explained the configuration options for Sitecore scheduled tasks. One notable detailed article can be found on the Sitecore Community Docs which reconfirmed my understanding of what triggers the scheduled tasks to run and how often the agent checks what tasks to be run. I played around with these settings and still couldn’t get my scheduled task to run. I then read a post on stack overflow which gave me a good pointer. I needed to check that the database agent was being initialised correctly, where you should see the following towards the start of the Sitecore logs: 1239988 17:25:38 INFO Scheduler - Adding agents9988 17:25:38 INFO Scheduler - Adding agent: Sitecore.Tasks.UrlAgent (interval: 00:15:00)9988 17:25:38 INFO Scheduler - Adding agent: Sitecore.Tasks.TaskDatabaseAgent (interval: 00:02:00) So i then looked back through my logs to see when this was last logged. I then looked at the tail of the file to see which configuration file was added or changed. I found that i had added “Include/zzz/InitializeSpeedBooster.config” to speed up the startup of Sitecore. This is an optional config when creating a new Sitecore instance using Sitecore SIM. I opened this config and spotted the issue straight away. To fix the issue but using the other speed boosting configuration, you can comment out the following line: 123&lt;processor type=\"Sitecore.Pipelines.Loader.InitializeScheduler, Sitecore.Kernel\"&gt; &lt;patch:delete /&gt;&lt;/processor&gt; This resolved my issue and now all Sitecore scheduled tasks and scheduled Powershell scripts now run, as per the schedule configuration. I hope this post will save someone else with the same scenario some time in resolving."},{"title":"No more wrappers with Sitecore fake db","permalink":"http://adamsimsy.com/2016/05/24/sitecore-fake-db/","text":"Just reviewed and started using this module after being frustrated with abstractions and getting buried in wrappers. No matter how good you are at managing your solution, you’ll end up with a mess of wrappers to be able to unit test every facet of Sitecore. Purist might not agree with the approach but for me it enables you to unit test wha is important, the logic and behaviours of the code you write that uses the Sitecore API. Nice work!https://marketplace.sitecore.net/Modules/Sitecore_FakeDb.aspx?authResult=success#"},{"title":"Starting my Sitecore blog","permalink":"http://adamsimsy.com/2016/05/14/starting-my-sitecore-blog/","text":"Hello Sitecore world!!! Since i began my career as a Sitecore developer more than 9 years ago when i joined the first Sitecore UK Partner Eduserv, i always intended to create a blog about my experiences with Sitecore to help others in the community and also to document my development as a Sitecore developer. I’ve made notes, thought “I’ll write that up later” and made to many excuses about being “to busy”. I’ve come a long way and in recent years focus on leading large teams of excellent Sitecore developers to deliver some great Sitecore solutions. I’m typically the Sitecore architect that is the interface between the business and the development team. Ensuring that solutions are delivered on time, to budget and more importantly delivering value for the business by developing a user centred solution. Over the next few weeks I’ll write up some of my notes on topics that are still relevant today. Beyond this I’ll write up my ideas on how Sitecore customers can get value out of the Sitecore platform. Most of which will focus more on people and processes over technology, which Sitecore customers and the development community are already doing well! Please do follow and contribute to this blog through comments on my blog posts. Thanks! Adamsimsy."}]}